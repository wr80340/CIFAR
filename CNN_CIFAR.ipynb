{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 24 17:28:26 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:18:00.0 Off |                  N/A |\r\n",
      "| 32%   50C    P0    65W / 250W |      3MiB / 11016MiB |     15%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils, datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.20 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.19<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wobbly-wildflower-30</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wr80340/uncategorized\" target=\"_blank\">https://wandb.ai/wr80340/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wr80340/uncategorized/runs/2k2qcwrw\" target=\"_blank\">https://wandb.ai/wr80340/uncategorized/runs/2k2qcwrw</a><br/>\n",
       "                Run data is saved locally in <code>/tf/liao/wandb/run-20210224_172834-2k2qcwrw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2k2qcwrw)</h1><iframe src=\"https://wandb.ai/wr80340/uncategorized/runs/2k2qcwrw\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f76e9a8b208>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)]) \n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "wandb.init(\"cifar-project\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 200\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE_CROPPED = 24\n",
    "LR = 1e-4\n",
    "\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM)\n",
    "optimizer = tf.keras.optimizers.Adam(lr = LR)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 1)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse training data\n",
    "def map_fun(image, label):    distorted_image = tf.image.random_crop(image, [IMAGE_SIZE_CROPPED,IMAGE_SIZE_CROPPED,3])\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(\n",
    "        distorted_image, lower=0.2, upper=1.8)\n",
    "    distorted_image = tf.image.per_image_standardization(distorted_image)\n",
    "    return distorted_image, label\n",
    "\n",
    "# parse testing data\n",
    "def map_fun_test(image, label):\n",
    "    distorted_image = tf.image.resize_with_crop_or_pad(image, IMAGE_SIZE_CROPPED,IMAGE_SIZE_CROPPED)\n",
    "    distorted_image = tf.image.per_image_standardization(distorted_image)\n",
    "    return distorted_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/image_ops_impl.py:1556: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset_train = dataset_train.map(map_fun)\n",
    "dataset_train = dataset_train.shuffle(1000)\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE)\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "dataset_test = dataset_test.map(map_fun_test)\n",
    "dataset_test = dataset_test.shuffle(1000)\n",
    "dataset_test = dataset_test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.cnn1 = tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu', input_shape = (32, 32, 3))\n",
    "        self.maxpool1 = tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2))\n",
    "        self.cnn2 = tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')\n",
    "        self.maxpool2 = tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=(2,2))\n",
    "\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(384, activation='relu')\n",
    "        self.drop = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(192, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "        self.batchnorm = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.cnn1(inputs)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        \n",
    "        x = self.cnn2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.batchnorm(x)\n",
    "\n",
    "        x = self.flat(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "cnn_model = CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = cnn_model(images)\n",
    "        loss = scce(labels, predictions)\n",
    "    grads = tape.gradient(loss, cnn_model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, cnn_model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "@tf.function\n",
    "def val_step(images, labels):\n",
    "    preds = cnn_model(images)\n",
    "    loss = scce(labels, preds)\n",
    "    test_loss(loss)\n",
    "    test_accuracy(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train accuracy 0.28, train loss 62.11, val accuracy 0.31, val loss 60.22\n",
      "Epoch 10, train accuracy 0.48, train loss 46.67, val accuracy 0.51, val loss 44.02\n",
      "Epoch 20, train accuracy 0.54, train loss 41.35, val accuracy 0.57, val loss 39.22\n",
      "Epoch 30, train accuracy 0.58, train loss 37.78, val accuracy 0.60, val loss 36.41\n",
      "Epoch 40, train accuracy 0.61, train loss 35.00, val accuracy 0.62, val loss 34.49\n",
      "Epoch 50, train accuracy 0.64, train loss 32.75, val accuracy 0.64, val loss 33.10\n",
      "Epoch 60, train accuracy 0.66, train loss 30.82, val accuracy 0.65, val loss 32.11\n",
      "Epoch 70, train accuracy 0.68, train loss 29.16, val accuracy 0.66, val loss 31.37\n",
      "Epoch 80, train accuracy 0.70, train loss 27.66, val accuracy 0.67, val loss 30.81\n",
      "Epoch 90, train accuracy 0.71, train loss 26.33, val accuracy 0.68, val loss 30.44\n",
      "Epoch 100, train accuracy 0.72, train loss 25.12, val accuracy 0.68, val loss 30.18\n",
      "Epoch 110, train accuracy 0.74, train loss 24.01, val accuracy 0.69, val loss 30.04\n",
      "Epoch 120, train accuracy 0.75, train loss 22.99, val accuracy 0.69, val loss 29.98\n",
      "Epoch 130, train accuracy 0.76, train loss 22.05, val accuracy 0.69, val loss 29.99\n",
      "Epoch 140, train accuracy 0.77, train loss 21.17, val accuracy 0.70, val loss 30.02\n",
      "Epoch 150, train accuracy 0.78, train loss 20.37, val accuracy 0.70, val loss 30.09\n",
      "Epoch 160, train accuracy 0.79, train loss 19.62, val accuracy 0.70, val loss 30.20\n",
      "Epoch 170, train accuracy 0.79, train loss 18.93, val accuracy 0.70, val loss 30.35\n",
      "Epoch 180, train accuracy 0.80, train loss 18.27, val accuracy 0.70, val loss 30.52\n",
      "Epoch 190, train accuracy 0.81, train loss 17.67, val accuracy 0.71, val loss 30.72\n"
     ]
    }
   ],
   "source": [
    "# training step \n",
    "for ep in range(EPOCH):\n",
    "    for (train_img, train_label), (val_img, val_label) in zip(dataset_train,dataset_test):\n",
    "        train_step(train_img, train_label)\n",
    "        val_step(val_img, val_label)\n",
    "    wandb.log({\"train accuracy\": train_accuracy.result().numpy(),\n",
    "               \"train loss \" : train_loss.result().numpy(),\n",
    "               \"val accuracy \" : test_accuracy.result().numpy(),\n",
    "               \"val loss \" : test_loss.result().numpy()})\n",
    "    if ep % 10 == 0: \n",
    "        tmp = \"Epoch {:0}, train accuracy {:.2f}, train loss {:.2f}, val accuracy {:.2f}, val loss {:.2f}\"\n",
    "        print(tmp.format(ep,\n",
    "                         train_accuracy.result().numpy(),\n",
    "                         train_loss.result().numpy(),\n",
    "                         test_accuracy.result().numpy(),\n",
    "                         test_loss.result().numpy()))\n",
    "train_loss.reset_states()\n",
    "train_accuracy.reset_states()\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
